```python
import torch
import torch.nn as nn
```


```python
inputs = torch.Tensor(1,1,28,28)
```


```python
print("텐서의 크기 : {}".format(inputs.shape))
```

    텐서의 크기 : torch.Size([1, 1, 28, 28])


# 1. Convolutional layer 구성

**1 layer**

- 입력 : 1채널
- 출력 : 32채널(특징맵 32개)
- 커널 : (1 x 32) x (3 x 3), 커널 사이즈 = 3 
- 패딩 : 1



```python
# 1채널 입력받아, 32채널 뽑아냄. 커널 사이즈는 3, 패딩은 1
conv1 = nn.Conv2d(1,32,3,padding=1)
```


```python
print(conv1)
```

    Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))


**2 layer**

- 입력 : 32채널
- 출력 : 64채널
- 커널 : (32 x 64) x (3 x 3), 커널 사이즈 = 3 
- 패딩 : 1


```python
conv2 = nn.Conv2d(32,64,kernel_size=3, padding=1)
print(conv2)
```

    Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))


**max pooling**

- nn.MaxPool2d(int) : int정수값을 넣으면, stride, kernel_size 모두 해당 int로 지정됨

- pool_kernel_size 가 2라는 것은, 2x2 kernel로 1개의 pool값을 만들겠다는 것. 가로/세로 모두 1/2씩 줄어들 것


```python
pool = nn.MaxPool2d(2)
print(pool)
```

    MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)


# 2. 연결

```
inputs.shape = 1,1,28,28 (batch x channel x width x height)
conv1 = 1->32channel

conv1(inputs) -> 1,32,28,28
* 32 : conv1 이 1channel을 받아 32channel을 출력하기 때문
* 28x28 유지 : padding이 1이고, kernel_size = 3이기 때문 (만약, kernel_size가 5였다면, 25x25로 축소될 것)

```


```python
out = conv1(inputs)
print(out.shape)
```

    torch.Size([1, 32, 28, 28])



```python
out = pool(out)
print(out.shape)
```

    torch.Size([1, 32, 14, 14])



```python
out = conv2(out)
print(out.shape)
```

    torch.Size([1, 64, 14, 14])



```python
out = pool(out)
print(out.shape)
```

    torch.Size([1, 64, 7, 7])



```python
out.size(0)
```




    1




```python
out.size(1)
```




    64




```python
out.size(2)
```




    7




```python
out.size(3)
```




    7




```python
# Flatten
# 첫번째 차원인 배치 차원은 그대로 두고, 나머지를 펼치기
out = out.view(out.size(0),-1)
print(out.shape)
```

    torch.Size([1, 3136])



```python
# F_C layer
fc = nn.Linear(3136,10)  # input_dim = 3,136, output_dim = 10
output = fc(out)
print(output.shape)
```

    torch.Size([1, 10])


# 3. MNIST 분류_CNN


```python
import torch
import torchvision.datasets as dsets
import torchvision.transforms as transforms
import torch.nn.init
```


```python
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# 랜덤 시드 고정
torch.manual_seed(777)

# GPU 사용일 경우, 랜덤시드 고정
if device == 'GPU':
    torch.cuda.manual_seed_all(777)
```


```python
learning_rate = 0.001
training_epochs = 15
batch_size = 100
```

### 0. dataloader로 dataset 정의


```python
mnist_train = dsets.MNIST(root='MNIST_data/',
                          train=True,
                          transform=transforms.ToTensor(),
                          download=True)
mnist_test = dsets.MNIST(root='MNIST_data/',
                         train=False,
                         transform=transforms.ToTensor(),
                         download=True)
```

    Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz



    HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))


    Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw
    Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz



    HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))


    Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw
    Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz



    HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))


    Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw
    Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz



    HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))


    Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw
    Processing...
    Done!



```python
data_loader = torch.utils.data.DataLoader(dataset=mnist_train,
                                          batch_size=batch_size,
                                          shuffle=True,
                                          drop_last=True)
```

### 1. model 구성


```python
class CNN(torch.nn.Module):
    def __init__(self):
        super(CNN,self).__init__()
        
        # layer 1
        # imginput = (?,28,28,1)
        # conv = (?,28,28,32)
        # pool = (?,14,14,32)
        # conv - activate - pool
        self.layer1 = torch.nn.Sequential(
            torch.nn.Conv2d(1,32,kernel_size=3,stride=1,padding=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2,stride=2))
        
        # layer 2
        # imginput = (?,14,14,32)
        # conv = (?,14,14,64)
        # pool = (?,7,7,64)
        # conv - activate - pool
        self.layer2 = torch.nn.Sequential(
            torch.nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2,stride=2))
        
        # F_C layer
        # (?,7*7*64) -> (?,10)
        self.fc = torch.nn.Linear(7*7*64,10,bias=True)
        
        # 전결합층 한정으로 가중치 초기화
        torch.nn.init.xavier_uniform_(self.fc.weight)
    
    def forward(self,x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.view(out.size(0),-1) # Flatten
        out = self.fc(out)
        
        return out    
```


```python
model = CNN().to(device)
```


```python
criterion = torch.nn.CrossEntropyLoss().to(device)
optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)
```


```python
total_batch = len(data_loader)
print("총 배치 수 : {}".format(total_batch))
```

    총 배치 수 : 600



```python
loss_list = []

for epoch in range(training_epochs):
    for idx, samples in enumerate(data_loader):
        # batch단위로 100개씩 한번에 끌어와 학습시킴(이전에는 1개씩 끌어왔음)
        
        x_train, y_train = samples
        
        # forward
        pred = model(x_train)
        cost = criterion(pred,y_train)
        
        # backward
        optimizer.zero_grad()
        cost.backward()
        optimizer.step()
        
        avg_cost = cost.item() / total_batch
        
        loss_list.append(avg_cost) # avg_cost : 1개 sample에 대한 평균 코스트!
        
    print("epoch : {}, cost : {}".format(epoch+1, avg_cost))
        
```

    epoch : 1, cost : 0.00013011763493220012
    epoch : 2, cost : 5.628721167643865e-05
    epoch : 3, cost : 0.00017973252882560095
    epoch : 4, cost : 0.00010379734138647715
    epoch : 5, cost : 1.814311370253563e-05
    epoch : 6, cost : 0.00012482058256864547
    epoch : 7, cost : 1.2282579361150662e-05
    epoch : 8, cost : 6.858360332747301e-06
    epoch : 9, cost : 0.00010552693158388137
    epoch : 10, cost : 4.82761301100254e-06
    epoch : 11, cost : 2.960771477470795e-06
    epoch : 12, cost : 2.0371517166495323e-06
    epoch : 13, cost : 1.5624599958149096e-06
    epoch : 14, cost : 1.4706586177150408e-05
    epoch : 15, cost : 8.326259558089078e-07


### 2. Test


```python
# 학습을 진행하지 않을 것이므로, torch.no_grad()
with torch.no_grad():
    x_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)
    y_test = mnist_test.test_labels.to(device)
    
    pred = model(x_test)
    correct_predcition = torch.argmax(pred,1)  == y_test
    accuracy = correct_predcition.float().mean()
    print("accuracy : ",accuracy.item())
```

    accuracy :  0.9864000082015991

