# 04.03 스케일링

## 1. 조건수 (Condition No.)

**보스턴 집값 데이터의 큰 조건수 예제**


```python
from sklearn.datasets import load_boston

boston = load_boston()

dfX = pd.DataFrame(boston.data, columns=boston.feature_names)
dfy = pd.DataFrame(boston.target, columns=["MEDV"])
df = pd.concat([dfX, dfy], axis=1)
```


```python
model = sm.OLS.from_formula("MEDV ~ " + "+".join(boston.feature_names),df)
result = model.fit()
print(result.summary())
```

                                OLS Regression Results                            
    ==============================================================================
    Dep. Variable:                   MEDV   R-squared:                       0.741
    Model:                            OLS   Adj. R-squared:                  0.734
    Method:                 Least Squares   F-statistic:                     108.1
    Date:                Sun, 17 May 2020   Prob (F-statistic):          6.72e-135
    Time:                        19:12:40   Log-Likelihood:                -1498.8
    No. Observations:                 506   AIC:                             3026.
    Df Residuals:                     492   BIC:                             3085.
    Df Model:                          13                                         
    Covariance Type:            nonrobust                                         
    ==============================================================================
                     coef    std err          t      P>|t|      [0.025      0.975]
    ------------------------------------------------------------------------------
    Intercept     36.4595      5.103      7.144      0.000      26.432      46.487
    CRIM          -0.1080      0.033     -3.287      0.001      -0.173      -0.043
    ZN             0.0464      0.014      3.382      0.001       0.019       0.073
    INDUS          0.0206      0.061      0.334      0.738      -0.100       0.141
    CHAS           2.6867      0.862      3.118      0.002       0.994       4.380
    NOX          -17.7666      3.820     -4.651      0.000     -25.272     -10.262
    RM             3.8099      0.418      9.116      0.000       2.989       4.631
    AGE            0.0007      0.013      0.052      0.958      -0.025       0.027
    DIS           -1.4756      0.199     -7.398      0.000      -1.867      -1.084
    RAD            0.3060      0.066      4.613      0.000       0.176       0.436
    TAX           -0.0123      0.004     -3.280      0.001      -0.020      -0.005
    PTRATIO       -0.9527      0.131     -7.283      0.000      -1.210      -0.696
    B              0.0093      0.003      3.467      0.001       0.004       0.015
    LSTAT         -0.5248      0.051    -10.347      0.000      -0.624      -0.425
    ==============================================================================
    Omnibus:                      178.041   Durbin-Watson:                   1.078
    Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126
    Skew:                           1.521   Prob(JB):                    8.84e-171
    Kurtosis:                       8.281   Cond. No.                     1.51e+04
    ==============================================================================
    
    Warnings:
    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
    [2] The condition number is large, 1.51e+04. This might indicate that there are
    strong multicollinearity or other numerical problems.


**큰 Condition Number - warning 메시지**


```python
# 표준편차 확인
# 각 독립변수 별 표준편차가 제각각, 범위도 매우 다양한 것을 확인할 수 있음 -> 스케일링이 필요함

dfX.describe().loc['std']
```




    CRIM         8.601545
    ZN          23.322453
    INDUS        6.860353
    CHAS         0.253994
    NOX          0.115878
    RM           0.702617
    AGE         28.148861
    DIS          2.105710
    RAD          8.707259
    TAX        168.537116
    PTRATIO      2.164946
    B           91.294864
    LSTAT        7.141062
    Name: std, dtype: float64



## 스케일링 : formula문자열에서 scale() 명령으로 각 독립변수 스케일링 가능


```python
# 중요 : 범주형 변수는 scaling을 하지 않는다!! -> 범주형 변수 제외한 feature_names 생성

features_names = list(boston.feature_names)
features_names.remove('CHAS')
features_names
```




    ['CRIM',
     'ZN',
     'INDUS',
     'NOX',
     'RM',
     'AGE',
     'DIS',
     'RAD',
     'TAX',
     'PTRATIO',
     'B',
     'LSTAT']




```python
# 새로운 formula문자열 생성 (스케일링 명령 포함)

features_names = ["scale({})".format(name) for name in features_names] + ['CHAS']
features_names
```




    ['scale(CRIM)',
     'scale(ZN)',
     'scale(INDUS)',
     'scale(NOX)',
     'scale(RM)',
     'scale(AGE)',
     'scale(DIS)',
     'scale(RAD)',
     'scale(TAX)',
     'scale(PTRATIO)',
     'scale(B)',
     'scale(LSTAT)',
     'CHAS']




```python
# OLS 모델 생성 및 학습

model = sm.OLS.from_formula('MEDV ~' + "+".join(features_names),df)
result = model.fit()
print(result.summary())
```

                                OLS Regression Results                            
    ==============================================================================
    Dep. Variable:                   MEDV   R-squared:                       0.741
    Model:                            OLS   Adj. R-squared:                  0.734
    Method:                 Least Squares   F-statistic:                     108.1
    Date:                Sun, 17 May 2020   Prob (F-statistic):          6.72e-135
    Time:                        19:18:45   Log-Likelihood:                -1498.8
    No. Observations:                 506   AIC:                             3026.
    Df Residuals:                     492   BIC:                             3085.
    Df Model:                          13                                         
    Covariance Type:            nonrobust                                         
    ==================================================================================
                         coef    std err          t      P>|t|      [0.025      0.975]
    ----------------------------------------------------------------------------------
    Intercept         22.3470      0.219    101.943      0.000      21.916      22.778
    scale(CRIM)       -0.9281      0.282     -3.287      0.001      -1.483      -0.373
    scale(ZN)          1.0816      0.320      3.382      0.001       0.453       1.710
    scale(INDUS)       0.1409      0.421      0.334      0.738      -0.687       0.969
    scale(NOX)        -2.0567      0.442     -4.651      0.000      -2.926      -1.188
    scale(RM)          2.6742      0.293      9.116      0.000       2.098       3.251
    scale(AGE)         0.0195      0.371      0.052      0.958      -0.710       0.749
    scale(DIS)        -3.1040      0.420     -7.398      0.000      -3.928      -2.280
    scale(RAD)         2.6622      0.577      4.613      0.000       1.528       3.796
    scale(TAX)        -2.0768      0.633     -3.280      0.001      -3.321      -0.833
    scale(PTRATIO)    -2.0606      0.283     -7.283      0.000      -2.617      -1.505
    scale(B)           0.8493      0.245      3.467      0.001       0.368       1.331
    scale(LSTAT)      -3.7436      0.362    -10.347      0.000      -4.454      -3.033
    CHAS               2.6867      0.862      3.118      0.002       0.994       4.380
    ==============================================================================
    Omnibus:                      178.041   Durbin-Watson:                   1.078
    Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126
    Skew:                           1.521   Prob(JB):                    8.84e-171
    Kurtosis:                       8.281   Cond. No.                         10.6
    ==============================================================================
    
    Warnings:
    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.


**큰 Condition Number - warning 메시지가 사라진 걸 확인**
