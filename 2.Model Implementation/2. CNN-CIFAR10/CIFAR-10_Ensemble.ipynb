{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIFAR-10_Ensemble.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPpTwfkeyAqYDze8zxc/QJU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IcEGP0bWuHUE","colab_type":"text"},"source":["\n","\n","[참고 코드]\n","https://github.com/kuangliu/pytorch-cifar/blob/master/models/vgg.py\n"]},{"cell_type":"code","metadata":{"id":"jxJY5fo8zLtq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599829562694,"user_tz":-540,"elapsed":967,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}},"outputId":"e278f5ff-13f3-4b6e-b754-b6d67ff0a648"},"source":["!mkdir results"],"execution_count":1,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘results’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mRLuF6N8l9eO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599829563106,"user_tz":-540,"elapsed":1359,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}},"outputId":"152b2df8-b2b3-4af9-9c93-bdff6d8b1199"},"source":["!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["data  results  results_highAcc\tsample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hsR57zgpu-EK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599829563106,"user_tz":-540,"elapsed":1342,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}},"outputId":"71149698-860d-458c-91de-17870a22c6c8"},"source":["!cd results\n","!ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":["data  results  results_highAcc\tsample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wga97J7BvCxZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599829563411,"user_tz":-540,"elapsed":1628,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}},"outputId":"bf251d74-8493-4624-aa22-93c0bb604a00"},"source":["!cat results"],"execution_count":4,"outputs":[{"output_type":"stream","text":["cat: results: Is a directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-yLbCNo4zbfi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1599829564128,"user_tz":-540,"elapsed":2324,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}},"outputId":"3ae274ff-daba-4427-aa98-fdf3a41bcf46"},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import argparse\n","import numpy as np\n","import time\n","from copy import deepcopy # Add Deepcopy for args\n","import seaborn as sns \n","import matplotlib.pyplot as plt"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"H2E1DK8PzeFh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1599829565670,"user_tz":-540,"elapsed":3850,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}},"outputId":"b03cc3b3-df72-4425-fb03-2d0505c7f323"},"source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainset, valset = torch.utils.data.random_split(trainset, [40000, 10000])\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","partition = {'train': trainset, 'val':valset, 'test':testset}"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6M0XwZvnOZ7b","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1599829565671,"user_tz":-540,"elapsed":3836,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}},"outputId":"469db43e-90df-49ff-a4b4-ae15cac23671"},"source":["testset"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset CIFAR10\n","    Number of datapoints: 10000\n","    Root location: ./data\n","    Split: Test\n","    StandardTransform\n","Transform: Compose(\n","               ToTensor()\n","               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n","           )"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"W1qHRjXRzgVC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599829565672,"user_tz":-540,"elapsed":3823,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}},"outputId":"d6573782-90c3-47b6-fb9b-0df3dd038b30"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","torch.manual_seed(777)\n","if device=='cuda':\n","    torch.cuda.manual_seed_all(777)\n","\n","print('현재 device :', device)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["현재 device : cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5faR7kxP0brv","colab_type":"text"},"source":["# 1. Model(MLP)"]},{"cell_type":"code","metadata":{"id":"vCoFWGGIzq7l","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599829565672,"user_tz":-540,"elapsed":3812,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["class MLP(nn.Module):\n","    \n","    def __init__(self, in_dim, out_dim, hid_dim, n_layer, act, batch_normal, dropout_p, weight_init):\n","        super(MLP,self).__init__()\n","        self.in_dim = in_dim\n","        self.out_dim = out_dim\n","        self.hid_dim = hid_dim\n","        self.n_layer = n_layer  # n_layer = hid_dim(1) + ... + hid_dim(n-1) + out_dim(n)\n","        self.act = act\n","        self.batch_normal = batch_normal\n","        self.dropout = dropout_p\n","        \n","        #===Create sequence space===#\n","        self.linears = nn.ModuleList()\n","        self.batch_normals = nn.ModuleList()\n","        \n","        self.fc1 = nn.Linear(self.in_dim, self.hid_dim)\n","        for idx in range(n_layer-1):\n","            self.linears.append(nn.Linear(self.hid_dim, self.hid_dim))\n","            # 레이어 마다 batch_normalization 시행 예정-> [linear - BN - activation] 반복\n","            if self.batch_normal == True:\n","                self.batch_normals.append(nn.BatchNorm1d(hid_dim))\n","        self.fc2 = nn.Linear(self.hid_dim, self.out_dim)\n","        \n","        #===Create Activation Function===#\n","        if self.act == 'sigmoid':\n","            self.act = nn.Sigmoid()\n","        elif self.act == 'relu':\n","            self.act = nn.ReLU()\n","        elif self.act == 'tanh':\n","            self.act = nn.Tanh()\n","        elif self.act == 'leaky_relu':\n","            self.act = nn.LeakyReLU()\n","        else:\n","            raise ValueError(\"no valid activation function selected(sigmoid, relu, leaky_relu, tanh)\")\n","            \n","        #===Create Regularization layer===#\n","        # dropout\n","        self.dropout = nn.Dropout(self.dropout)\n","        # weight_initialization\n","        if weight_init == 'xavier':\n","            self.xavier_init()\n","        elif weight_init == 'he':\n","            self.he_init()\n","        else:\n","            raise ValueError(\"no valid weight_initializer selected(xavier, he)\")\n","            \n","    def xavier_init(self):\n","        for linear in self.linears:\n","            nn.init.xavier_normal_(linear.weight)\n","            linear.bias.data.fill_(0.01)\n","    \n","    def he_init(self):\n","        for linear in self.linears:\n","            torch.nn.init.kaiming_normal_(linear.weight)\n","            linear.bias.data.fill_(0.01)\n","        \n","    def forward(self,x):\n","        out = self.act(self.fc1(x))\n","        \n","                                        #===hidden layer===#\n","        # 레이어 마다 batch_normalization 시행 예정-> [weight_init - linear - BN - activation - dropout] 반복\n","        # batch_norm, dropout 은 model.train()에서만 ON\n","        # batch_norm, dropout 은 hidden layer에서만 적용해야 함!\n","        for idx in range(len(self.linears)):\n","            out = self.linears[idx](out)\n","            if self.batch_normals:\n","                out = self.batch_normals[idx](out)\n","            out = self.act(out)\n","            out = self.dropout(out)\n","                                        #===hidden layer===#\n","        \n","        out = self.fc2(out)\n","        return out\n","  "],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_VGGYxTzsk6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599829565674,"user_tz":-540,"elapsed":3810,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["# __init__(self, in_dim, out_dim, hid_dim, n_layer, act, batch_normal, dropout_p, weight_init):\n","\n","# model = MLP(3072,10,100,4,'leaky_relu',batch_normal=True,dropout_p=0.1,weight_init='he')"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DYzd8OnLJxv0","colab_type":"text"},"source":["# 1. Model(CNN)"]},{"cell_type":"code","metadata":{"id":"O-oLn6mnJwBe","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599829565674,"user_tz":-540,"elapsed":3807,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN,self).__init__()\n","        \n","        self.conv_layer1 = nn.Sequential(\n","            nn.Conv2d(3,64,kernel_size=3,padding=1,stride=1),\n","            nn.Conv2d(64,256,kernel_size=5,padding=2,stride=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","\n","        self.fc1 = nn.Linear(65536,10)\n","\n","    def forward(self,x):\n","        out = self.conv_layer1(x)\n","        out = out.view(out.size(0),-1)\n","        out = self.fc1(out)\n","        return out\n","\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"A5a56X6gTmgK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599829565938,"user_tz":-540,"elapsed":4067,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["# def dimension_check():\n","#     model = CNN()\n","#     x = torch.rand(2,3,32,32)\n","#     out = model(x)\n","#     print(out.shape)\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cnuiun3gUqV4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599829565939,"user_tz":-540,"elapsed":4064,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["# dimension_check()"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NC3ExgJmY2h3","colab_type":"text"},"source":["# 1. Model(CNN_VGG)"]},{"cell_type":"code","metadata":{"id":"NCU7Xb58Y10s","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599829565939,"user_tz":-540,"elapsed":4061,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["# M : maxpooling 단계, int : out channel 숫자 \n","# M 은 모두 5개 ==>> 전체 width = height = 32 니까, 5번의 maxpooling 통해 receptive field = 1 (32/2/2/2/2/2 = 1) 로 만들어, receptive field = 전체 image로 만들겠다.\n","# 최종적으로 뽑아낸 복잡한 feature들로 receptive field를 전체 이미지 범위로 놓고, 모든 이미지에 이 feature map을 만들어내겠다. 는 것.\n","cfg = {\n","    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n","    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n","}"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"wPCteE1UY7ah","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599829565940,"user_tz":-540,"elapsed":4058,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["# out_dim, args.batch_normal, args.weight_init = 'he', args.act\n","\n","class CNN_VGG(nn.Module):\n","    def __init__(self, model_code, in_channels, batch_normal, out_dim, weight_init, act, dropout_p):\n","        super(CNN_VGG,self).__init__()\n","\n","        #===Create Activation Function===#\n","        if act == 'sigmoid':\n","            self.act = nn.Sigmoid()\n","        elif act == 'relu':\n","            self.act = nn.ReLU()\n","        elif act == 'tanh':\n","            self.act = nn.Tanh()\n","        elif act == 'leaky_relu':\n","            self.act = nn.LeakyReLU()\n","        else:\n","            raise ValueError(\"no valid activation function selected(sigmoid, relu, leaky_relu, tanh)\")\n","\n","        #===Convolutional layer sequence===#\n","        self.layers = self._make_layers(model_code, in_channels, batch_normal)\n","\n","        #===Fully-connected layer : [ (weight_init - linear - activation - dropout) - output linear ]===#\n","        self.dropout = nn.Dropout(dropout_p)\n","        self.classifier = nn.Sequential(nn.Linear(512*1*1, 256),\n","                                        self.act,\n","                                        self.dropout,\n","                                        nn.Linear(256, out_dim))\n","        # 마지막 output layer에는 activation function 하지 않는다. softmax가 loss_function에 포함되어있기 때문에.\n","\n","        #===weight_initialization===#\n","        if weight_init == 'xavier':\n","            self.xavier_init()\n","        elif weight_init == 'he':\n","            self.he_init()\n","        else:\n","            raise ValueError(\"no valid weight_initializer selected(xavier, he)\")\n","        \n","\n","    # _ : private method, class 안에서만 활용되는 함수. global scope가 아님.\n","    def _make_layers(self, model_code, in_channels, batch_normal):\n","\n","        # (conv + relu) + maxpool\n","        layers = []\n","        \n","        for x in cfg[model_code]:\n","            # + maxpool\n","            if x == 'M':\n","                layers.append(nn.MaxPool2d(2))\n","\n","            # # + conv + BN + relu\n","            # else: \n","            #     # conv\n","            #     layers.append(nn.Conv2d(in_channels = in_channels, out_channels = x, kernel_size=3, padding=1, stride=1))\n","            #     # BN\n","            #     if batch_normal == True:\n","            #         layers.append(nn.BatchNorm2d(x))\n","            #     # relu\n","            #     layers.append(self.act)\n","            #     in_channels=x\n","\n","            # + conv + relu + BN\n","            else: \n","                # conv\n","                layers.append(nn.Conv2d(in_channels = in_channels, out_channels = x, kernel_size=3, padding=1, stride=1))\n","                # relu\n","                layers.append(self.act) \n","                # BN\n","                if batch_normal == True:\n","                    layers.append(nn.BatchNorm2d(x))\n","                in_channels=x\n","\n","        # *layers : layers안에 들어있는 object들을 가변길이로 Sequential method에 argument로 넣기 위해 *붙임\n","        return nn.Sequential(*layers)\n","\n","    def forward(self,x):\n","        out = self.layers(x)\n","        out = out.view(out.size(0),-1)  # flatten\n","        out = self.classifier(out)\n","        return out\n","\n","    def xavier_init(self):\n","        for linear in self.classifier:\n","            if linear != self.act and linear != self.dropout:\n","                nn.init.xavier_normal_(linear.weight)\n","                linear.bias.data.fill_(0.01)\n","    \n","    def he_init(self):\n","        for linear in self.classifier:\n","            if linear != self.act and linear != self.dropout:\n","                torch.nn.init.kaiming_normal_(linear.weight)\n","                linear.bias.data.fill_(0.01)\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3opLHDXcfY1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599829565940,"user_tz":-540,"elapsed":4053,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["# def dimension_check():\n","#     model = CNN_VGG('VGG11', in_channels = 3) \n","#     x = torch.rand(2,3,32,32)\n","#     out = model(x)\n","#     print(out.shape)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"wWEGzfsxc7t-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599829565941,"user_tz":-540,"elapsed":4050,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["# dimension_check()"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iaT-4tXi0gmq","colab_type":"text"},"source":["# 2. Train"]},{"cell_type":"code","metadata":{"id":"TYZTZ3pRzuWS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599829565941,"user_tz":-540,"elapsed":4046,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["def train(model, partition, optimizer, criterion, args):\n","    # input data preparation\n","    trainloader = torch.utils.data.DataLoader(partition['train'], \n","                                              batch_size=args.train_batch_size, \n","                                              shuffle=True, num_workers=2)\n","    model.train()\n","    \n","    train_loss = 0.0\n","    accuracy_batch = 0.0\n","    total_sample = 0 \n","    for i, samples in enumerate(trainloader):\n","        x_data, y_label = samples\n","        # Convolutional layer input을 위해, MLP와 달리, 4차원 텐서([256,3,32,32])를 그대로 input([batch,channel,width,height])\n","        # train, validate, test 모두 flatten input 제거\n","        # x_data = x_data.view(-1,3072) \n","        x_data = x_data.to(device)\n","        y_label = y_label.to(device)\n","        \n","        # forward\n","        output = model(x_data)\n","        cost = criterion(output, y_label)\n","        \n","        # backward\n","        optimizer.zero_grad()\n","        cost.backward()\n","        optimizer.step()\n","        \n","        train_loss += cost.item()\n","        _, predicted_label = torch.max(output, dim=1)\n","        correct = predicted_label == y_label\n","        accuracy_batch += correct.float().sum().item()\n","        \n","        total_sample += y_label.size(0)\n","    \n","    \n","    # batch 당 평균 loss( len(trainloader) == batch 갯수 )\n","    train_loss_batch = train_loss / len(trainloader) \n","    # 모든 sample의 평균 accuracy\n","    train_acc_batch = (accuracy_batch / total_sample)*100\n","\n","    # 학습 후의 model을 return해서, 이후 validate 등에 넣어 활용할 예정\n","    return model, train_loss_batch, train_acc_batch\n","  "],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e2aQ0pfn0iej","colab_type":"text"},"source":["# 2. Validate"]},{"cell_type":"code","metadata":{"id":"YOAvAp6Uz6EB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599829565942,"user_tz":-540,"elapsed":4044,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["def validate(model, partition, criterion, args):\n","    valloader = torch.utils.data.DataLoader(partition['val'], \n","                                            batch_size=args.test_batch_size, \n","                                            shuffle=False, num_workers=2)\n","    model.eval()\n","    \n","    val_loss = 0.0\n","    accuracy_batch = 0.0\n","    total_sample = 0\n","    with torch.no_grad():\n","        for samples in valloader:\n","            x_data, y_label = samples\n","            # x_data = x_data.view(-1,3072)\n","            x_data = x_data.to(device)\n","            y_label = y_label.to(device)\n","            \n","            # forward\n","            output = model(x_data)\n","            cost = criterion(output, y_label)\n","            \n","            # backward (X)\n","            \n","            val_loss += cost.item()\n","            _, predicted_label = torch.max(output, dim=1)\n","            correct = predicted_label == y_label\n","            accuracy_batch += correct.float().sum().item()\n","            \n","            total_sample += y_label.size(0)\n","            \n","        val_loss_batch = val_loss / len(valloader) \n","        val_acc_batch = (accuracy_batch / total_sample)*100\n","    \n","    return val_loss_batch, val_acc_batch"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y8SrSAGC0kTP","colab_type":"text"},"source":["# 3. Test"]},{"cell_type":"code","metadata":{"id":"mDBx6ulfz7SW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599829565942,"user_tz":-540,"elapsed":4040,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["def test(model, partition, args):\n","    testloader = torch.utils.data.DataLoader(partition['test'], \n","                                             batch_size=args.test_batch_size, \n","                                             shuffle=False, num_workers=2)\n","    model.eval()\n","    \n","    accuracy_batch = 0.0\n","    total_sample = 0\n","    predicted_labels = []\n","    y_labels = []\n","    with torch.no_grad():\n","        for samples in testloader:\n","            x_data, y_label = samples\n","            # x_data = x_data.view(-1,3072)\n","            x_data = x_data.to(device)\n","            y_label = y_label.to(device)\n","            \n","            # forward (X)\n","\n","            # backward (X)\n","            \n","            output = model(x_data)\n","            _, predicted_label = torch.max(output, dim=1)\n","            correct = predicted_label == y_label\n","            accuracy_batch += correct.float().sum().item()\n","            \n","            predicted_labels.append(predicted_label)\n","            y_labels.append(y_label)\n","\n","            total_sample += y_label.size(0)\n","            \n","        test_acc_batch = (accuracy_batch / total_sample)*100\n","    \n","    return test_acc_batch, predicted_labels, y_labels"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MLzgCj1V0l9K","colab_type":"text"},"source":["# 4. Experiment function"]},{"cell_type":"code","metadata":{"id":"BGrdlUwZz_24","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599829565943,"user_tz":-540,"elapsed":4038,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["def experiment(partition,args):\n","    \n","    # model = MLP(args.in_dim, args.out_dim, args.hid_dim,\n","    #             args.n_layer, args.act,\n","    #             args.batch_normal, args.dropout_p, args.weight_init)\n","    \n","    # model = CNN()\n","\n","    model = CNN_VGG(model_code=args.model_code, in_channels=args.in_channels,\n","                    batch_normal = args.batch_normal, out_dim = args.out_dim, \n","                    weight_init = args.weight_init, act = args.act,\n","                    dropout_p = args.dropout_p)\n","    \n","    model.to(device)\n","    \n","    # Loss function\n","    criterion = nn.CrossEntropyLoss()\n","    \n","    # Optimizer\n","    if args.optim == 'SGD':\n","        optimizer = optim.SGD(model.parameters(), lr = args.lr, weight_decay = args.l2)\n","    elif args.optim == 'RMSprop':\n","        optimizer = optim.RMSprop(model.parameters(), lr = args.lr, weight_decay = args.l2)\n","    elif args.optim == 'ADAM':\n","        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2)\n","    else:\n","        raise ValueError(\"no valid optimizer selected(SGD, RMSprop, ADAM)\")\n","        \n","    # Create loss, accuracy list for visualization(seaborn)\n","    # epoch-wise loss, accuracy\n","    train_losses, val_losses = [], []\n","    train_accs, val_accs = [], []\n","    \n","    # loop (train / val)\n","    for epoch in range(args.epoch+1):\n","        ts = time.time()\n","        \n","        model, train_loss_batch, train_acc_batch = train(model, partition, optimizer, criterion, args)\n","        val_loss_batch, val_acc_batch = validate(model, partition, criterion, args)\n","        \n","        te = time.time()\n","        \n","        train_losses.append(train_loss_batch)\n","        val_losses.append(val_loss_batch)\n","        train_accs.append(train_acc_batch)\n","        val_accs.append(val_acc_batch)\n","        \n","        print('Epoch {}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.2f}/{:2.2f}.\\\n","              Took {:2.2f} sec'.format(epoch, train_acc_batch, val_acc_batch, train_loss_batch, val_loss_batch, te-ts))\n","    \n","    test_acc_batch, predicted_labels, y_labels = test(model, partition, args)\n","    \n","    # # to keep track of the result of each experiment\n","    result = {}\n","    result['train_losses'] = train_losses\n","    result['val_losses'] = val_losses\n","    result['train_accs'] = train_accs\n","    result['val_accs'] = val_accs\n","    result['train_acc'] = train_acc_batch\n","    result['val_acc'] = val_acc_batch\n","    result['test_acc'] = test_acc_batch\n","    \n","    # vars(object) : object가 갖는 attribute를 return! (result의 experiment arguments를 return하기 위함\n","    # vars(object) : object의 attribute를 dictionary 로 return!\n","    return vars(args), result, test_acc_batch, predicted_labels, y_labels"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0LamIYkN0seP","colab_type":"text"},"source":["# 5. Save and Load"]},{"cell_type":"code","metadata":{"id":"mujWcFLw0B15","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599829565943,"user_tz":-540,"elapsed":4035,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["import hashlib\n","import json\n","from os import listdir\n","from os.path import isfile, join\n","import pandas as pd\n","\n","def save_exp_result(setting, result):\n","    exp_name = setting['exp_name'] \n","    del setting['epoch']\n","    del setting['test_batch_size']\n","\n","    hash_key = hashlib.sha1(str(setting).encode()).hexdigest()[:6]\n","    filename = './results/{}-{}.json'.format(exp_name, hash_key)\n","    # .updata : dictionary의 append와 같음 (result.update(setting) : result dict + setting dict)\n","    result.update(setting)\n","    with open(filename, 'w') as f:\n","        json.dump(result, f)\n","\n","    \n","def load_exp_result(exp_name):\n","    dir_path = './results'\n","    filenames = [f for f in listdir(dir_path) if isfile(join(dir_path, f)) if '.json' in f]\n","    list_result = []\n","    for filename in filenames:\n","        if exp_name in filename:\n","            with open(join(dir_path, filename), 'r') as infile:\n","                results = json.load(infile)\n","                list_result.append(results)\n","    df = pd.DataFrame(list_result) # .drop(columns=[])\n","    return df"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iXuTfPthnusL","colab_type":"text"},"source":["# 6. Experiment"]},{"cell_type":"code","metadata":{"id":"gx4ahmyxnvK7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599829565944,"user_tz":-540,"elapsed":4032,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["# # ====== Random Seed Initialization ====== #\n","# seed = 123\n","# np.random.seed(seed)\n","# torch.manual_seed(seed)\n","\n","# parser = argparse.ArgumentParser()\n","# args = parser.parse_args(\"\")\n","# args.exp_name = \"exp5_dropout_p_l2\"\n","\n","# # ====== Model Capacity ====== #\n","# # args.in_dim = 3072  # MLP 입력용\n","# args.out_dim = 10\n","# # args.hid_dim = 100  # MLP 입력용\n","# args.act = 'relu'\n","# args.model_code = 'VGG13'   # CNN_VGG\n","# args.in_channels = 3    # CNN_VGG\n","\n","# # ====== Regularization ======= #\n","# args.dropout_p = 0.2\n","# args.batch_normal = True\n","# args.l2 = 1e-5\n","# args.weight_init = 'he'\n","\n","# # ====== Optimizer & Training ====== #\n","# args.optim = 'ADAM' #'RMSprop' #SGD, RMSprop, ADAM...\n","# args.lr = 0.002\n","# args.epoch = 17\n","\n","# args.train_batch_size = 512\n","# args.test_batch_size = 1024\n","\n","# # ====== Experiment Variable ====== #\n","# name_var1 = 'model_code'\n","# name_var2 = 'dropout_p'\n","# list_var1 = ['VGG13','VGG19']\n","# list_var2 = [0.2]\n","\n","\n","# for var1 in list_var1:\n","#     for var2 in list_var2:\n","#         setattr(args, name_var1, var1)\n","#         setattr(args, name_var2, var2)\n","#         print(args)\n","                \n","#         setting, result = experiment(partition, deepcopy(args))\n","#         save_exp_result(setting, result)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKit3Om_8gxR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599831156675,"user_tz":-540,"elapsed":1594757,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}},"outputId":"a70830e4-32d5-42dd-e85c-b80fd439d1e4"},"source":["# model 1 (highAcc, VGG13, epoch=17, l2_coef = 1e-5, dropout_p = 0.2)\n","# ====== Random Seed Initialization ====== #\n","seed = 123\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","parser = argparse.ArgumentParser()\n","args1 = parser.parse_args(\"\")\n","args1.exp_name = \"exp6_high_acc_vgg13\"\n","\n","# ====== Model Capacity ====== #\n","# args.in_dim = 3072  # MLP 입력용\n","args1.out_dim = 10\n","# args.hid_dim = 100  # MLP 입력용\n","args1.act = 'relu'\n","args1.model_code = 'VGG13'   # CNN_VGG\n","args1.in_channels = 3    # CNN_VGG\n","\n","# ====== Regularization ======= #\n","args1.dropout_p = 0.2\n","args1.batch_normal = True\n","args1.l2 = 1e-5\n","args1.weight_init = 'he'\n","\n","# ====== Optimizer & Training ====== #\n","args1.optim = 'ADAM' #'RMSprop' #SGD, RMSprop, ADAM...\n","args1.lr = 0.002\n","args1.epoch = 15\n","\n","args1.train_batch_size = 512\n","args1.test_batch_size = 1024\n","\n","# ====== Experiment Variable ====== #\n","name_var1 = 'model_code'\n","name_var2 = 'dropout_p'\n","list_var1 = ['VGG13']\n","list_var2 = [0.2]\n","\n","\n","\n","# model 2 (highAcc, VGG19, epoch=17, l2_coef = 1e-5, dropout_p = 0.2)\n","# ====== Random Seed Initialization ====== #\n","seed = 123\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","parser = argparse.ArgumentParser()\n","args2 = parser.parse_args(\"\")\n","args2.exp_name = \"exp7_high_acc_vgg19\"\n","\n","# ====== Model Capacity ====== #\n","# args.in_dim = 3072  # MLP 입력용\n","args2.out_dim = 10\n","# args.hid_dim = 100  # MLP 입력용\n","args2.act = 'relu'\n","args2.model_code = 'VGG19'   # CNN_VGG\n","args2.in_channels = 3    # CNN_VGG\n","\n","# ====== Regularization ======= #\n","args2.dropout_p = 0.2\n","args2.batch_normal = True\n","args2.l2 = 1e-5\n","args2.weight_init = 'he'\n","\n","# ====== Optimizer & Training ====== #\n","args2.optim = 'ADAM' #'RMSprop' #SGD, RMSprop, ADAM...\n","args2.lr = 0.002\n","args2.epoch = 15\n","\n","args2.train_batch_size = 512\n","args2.test_batch_size = 1024\n","\n","# ====== Experiment Variable ====== #\n","name_var1 = 'model_code'\n","name_var2 = 'dropout_p'\n","list_var1 = ['VGG19']\n","list_var2 = [0.2]\n","\n","\n","# model 3 (Reg, VGG13, epoch=13, l2_coef = 1e-3, dropout_p = 0.5)\n","# ====== Random Seed Initialization ====== #\n","seed = 123\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","parser = argparse.ArgumentParser()\n","args3 = parser.parse_args(\"\")\n","args3.exp_name = \"exp8_Reg_vgg13\"\n","\n","# ====== Model Capacity ====== #\n","# args.in_dim = 3072  # MLP 입력용\n","args3.out_dim = 10\n","# args.hid_dim = 100  # MLP 입력용\n","args3.act = 'relu'\n","args3.model_code = 'VGG19'   # CNN_VGG\n","args3.in_channels = 3    # CNN_VGG\n","\n","# ====== Regularization ======= #\n","args3.dropout_p = 0.5\n","args3.batch_normal = True\n","args3.l2 = 1e-3\n","args3.weight_init = 'he'\n","\n","# ====== Optimizer & Training ====== #\n","args3.optim = 'ADAM' #'RMSprop' #SGD, RMSprop, ADAM...\n","args3.lr = 0.002\n","args3.epoch = 13\n","\n","args3.train_batch_size = 512\n","args3.test_batch_size = 1024\n","\n","# ====== Experiment Variable ====== #\n","name_var1 = 'model_code'\n","name_var2 = 'dropout_p'\n","list_var1 = ['VGG13']\n","list_var2 = [0.5]\n","\n","\n","# model 4 (Reg, VGG19, epoch=13, l2_coef = 1e-3, dropout_p = 0.5)\n","# ====== Random Seed Initialization ====== #\n","seed = 123\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","parser = argparse.ArgumentParser()\n","args4 = parser.parse_args(\"\")\n","args4.exp_name = \"exp9_Reg_vgg19\"\n","\n","# ====== Model Capacity ====== #\n","# args.in_dim = 3072  # MLP 입력용\n","args4.out_dim = 10\n","# args.hid_dim = 100  # MLP 입력용\n","args4.act = 'relu'\n","args4.model_code = 'VGG19'   # CNN_VGG\n","args4.in_channels = 3    # CNN_VGG\n","\n","# ====== Regularization ======= #\n","args4.dropout_p = 0.5\n","args4.batch_normal = True\n","args4.l2 = 1e-3\n","args4.weight_init = 'he'\n","\n","# ====== Optimizer & Training ====== #\n","args4.optim = 'ADAM' #'RMSprop' #SGD, RMSprop, ADAM...\n","args4.lr = 0.002\n","args4.epoch = 13\n","\n","args4.train_batch_size = 512\n","args4.test_batch_size = 1024\n","\n","# ====== Experiment Variable ====== #\n","name_var1 = 'model_code'\n","name_var2 = 'dropout_p'\n","list_var1 = ['VGG19']\n","list_var2 = [0.5]\n","\n","\n","args_list = [args1, args2, args3, args4]\n","\n","predicted_y_list = {}\n","test_y_list = {}\n","\n","for idx, args in enumerate(args_list):\n","\n","    setting, result, test_acc_batch, predicted_labels, y_labels = experiment(partition, deepcopy(args))\n","\n","    predicted_y_list[idx] = predicted_labels\n","    test_y_list[idx] = y_labels\n","\n","    save_exp_result(setting, result)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Epoch 0, Acc(train/val): 26.11/36.01, Loss(train/val) 2.16/1.70.              Took 20.31 sec\n","Epoch 1, Acc(train/val): 43.72/45.75, Loss(train/val) 1.51/1.49.              Took 20.71 sec\n","Epoch 2, Acc(train/val): 55.60/53.90, Loss(train/val) 1.23/1.26.              Took 21.46 sec\n","Epoch 3, Acc(train/val): 62.94/64.60, Loss(train/val) 1.03/0.98.              Took 21.71 sec\n","Epoch 4, Acc(train/val): 71.73/69.87, Loss(train/val) 0.81/0.87.              Took 21.44 sec\n","Epoch 5, Acc(train/val): 77.50/73.69, Loss(train/val) 0.65/0.76.              Took 21.43 sec\n","Epoch 6, Acc(train/val): 81.93/77.99, Loss(train/val) 0.53/0.66.              Took 21.46 sec\n","Epoch 7, Acc(train/val): 84.38/78.52, Loss(train/val) 0.46/0.66.              Took 21.54 sec\n","Epoch 8, Acc(train/val): 87.67/77.83, Loss(train/val) 0.37/0.71.              Took 21.45 sec\n","Epoch 9, Acc(train/val): 90.03/80.83, Loss(train/val) 0.30/0.63.              Took 21.41 sec\n","Epoch 10, Acc(train/val): 91.85/79.16, Loss(train/val) 0.24/0.73.              Took 21.46 sec\n","Epoch 11, Acc(train/val): 92.12/80.14, Loss(train/val) 0.23/0.70.              Took 21.46 sec\n","Epoch 12, Acc(train/val): 93.49/80.80, Loss(train/val) 0.19/0.73.              Took 21.46 sec\n","Epoch 13, Acc(train/val): 95.20/82.13, Loss(train/val) 0.15/0.68.              Took 21.41 sec\n","Epoch 14, Acc(train/val): 95.04/81.93, Loss(train/val) 0.15/0.74.              Took 21.50 sec\n","Epoch 15, Acc(train/val): 97.07/81.36, Loss(train/val) 0.09/0.82.              Took 21.46 sec\n","Epoch 0, Acc(train/val): 22.64/31.82, Loss(train/val) 2.20/1.78.              Took 27.95 sec\n","Epoch 1, Acc(train/val): 35.31/34.52, Loss(train/val) 1.67/1.98.              Took 28.13 sec\n","Epoch 2, Acc(train/val): 45.30/51.06, Loss(train/val) 1.48/1.36.              Took 28.02 sec\n","Epoch 3, Acc(train/val): 56.15/58.19, Loss(train/val) 1.23/1.16.              Took 28.00 sec\n","Epoch 4, Acc(train/val): 63.02/59.60, Loss(train/val) 1.05/1.28.              Took 28.01 sec\n","Epoch 5, Acc(train/val): 68.56/65.57, Loss(train/val) 0.91/0.97.              Took 28.10 sec\n","Epoch 6, Acc(train/val): 72.83/71.13, Loss(train/val) 0.78/0.85.              Took 28.04 sec\n","Epoch 7, Acc(train/val): 76.31/73.10, Loss(train/val) 0.69/0.78.              Took 28.08 sec\n","Epoch 8, Acc(train/val): 79.33/71.86, Loss(train/val) 0.62/0.88.              Took 28.09 sec\n","Epoch 9, Acc(train/val): 80.26/77.05, Loss(train/val) 0.59/0.73.              Took 27.98 sec\n","Epoch 10, Acc(train/val): 84.54/78.60, Loss(train/val) 0.47/0.68.              Took 28.10 sec\n","Epoch 11, Acc(train/val): 86.01/80.50, Loss(train/val) 0.43/0.64.              Took 28.11 sec\n","Epoch 12, Acc(train/val): 88.49/81.18, Loss(train/val) 0.36/0.63.              Took 28.08 sec\n","Epoch 13, Acc(train/val): 90.11/79.13, Loss(train/val) 0.30/0.76.              Took 28.13 sec\n","Epoch 14, Acc(train/val): 90.10/80.62, Loss(train/val) 0.31/0.65.              Took 28.11 sec\n","Epoch 15, Acc(train/val): 91.27/80.67, Loss(train/val) 0.28/0.73.              Took 28.08 sec\n","Epoch 0, Acc(train/val): 20.09/28.78, Loss(train/val) 2.19/1.84.              Took 28.02 sec\n","Epoch 1, Acc(train/val): 35.63/43.18, Loss(train/val) 1.69/1.52.              Took 28.11 sec\n","Epoch 2, Acc(train/val): 48.45/50.33, Loss(train/val) 1.43/1.36.              Took 28.04 sec\n","Epoch 3, Acc(train/val): 58.24/58.84, Loss(train/val) 1.20/1.16.              Took 28.07 sec\n","Epoch 4, Acc(train/val): 64.48/60.96, Loss(train/val) 1.03/1.12.              Took 28.07 sec\n","Epoch 5, Acc(train/val): 70.36/66.32, Loss(train/val) 0.88/0.98.              Took 28.08 sec\n","Epoch 6, Acc(train/val): 72.61/68.98, Loss(train/val) 0.82/0.96.              Took 28.09 sec\n","Epoch 7, Acc(train/val): 76.28/73.09, Loss(train/val) 0.73/0.85.              Took 28.02 sec\n","Epoch 8, Acc(train/val): 78.75/73.87, Loss(train/val) 0.65/0.80.              Took 28.14 sec\n","Epoch 9, Acc(train/val): 81.99/74.83, Loss(train/val) 0.57/0.80.              Took 28.02 sec\n","Epoch 10, Acc(train/val): 82.34/75.22, Loss(train/val) 0.56/0.81.              Took 28.11 sec\n","Epoch 11, Acc(train/val): 83.41/74.39, Loss(train/val) 0.52/0.83.              Took 28.04 sec\n","Epoch 12, Acc(train/val): 85.69/77.46, Loss(train/val) 0.47/0.75.              Took 28.03 sec\n","Epoch 13, Acc(train/val): 86.81/74.78, Loss(train/val) 0.43/0.82.              Took 28.14 sec\n","Epoch 0, Acc(train/val): 23.41/33.10, Loss(train/val) 2.17/1.72.              Took 28.07 sec\n","Epoch 1, Acc(train/val): 38.65/40.50, Loss(train/val) 1.63/1.54.              Took 28.05 sec\n","Epoch 2, Acc(train/val): 48.39/49.94, Loss(train/val) 1.40/1.37.              Took 28.08 sec\n","Epoch 3, Acc(train/val): 57.67/55.61, Loss(train/val) 1.20/1.25.              Took 28.03 sec\n","Epoch 4, Acc(train/val): 64.30/57.68, Loss(train/val) 1.04/1.21.              Took 28.19 sec\n","Epoch 5, Acc(train/val): 70.17/66.76, Loss(train/val) 0.88/0.95.              Took 28.14 sec\n","Epoch 6, Acc(train/val): 74.09/64.65, Loss(train/val) 0.78/1.09.              Took 28.01 sec\n","Epoch 7, Acc(train/val): 75.88/72.91, Loss(train/val) 0.73/0.79.              Took 28.00 sec\n","Epoch 8, Acc(train/val): 78.67/72.24, Loss(train/val) 0.65/0.86.              Took 28.07 sec\n","Epoch 9, Acc(train/val): 81.47/76.38, Loss(train/val) 0.58/0.76.              Took 28.08 sec\n","Epoch 10, Acc(train/val): 84.08/78.84, Loss(train/val) 0.50/0.67.              Took 27.99 sec\n","Epoch 11, Acc(train/val): 85.19/77.32, Loss(train/val) 0.47/0.69.              Took 28.11 sec\n","Epoch 12, Acc(train/val): 85.63/77.32, Loss(train/val) 0.45/0.73.              Took 28.03 sec\n","Epoch 13, Acc(train/val): 87.66/78.53, Loss(train/val) 0.40/0.69.              Took 27.97 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bh1Z-a7DMlsK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599832211773,"user_tz":-540,"elapsed":848,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":["# predicted_y_list ==> 4개 key, dict형, 모든 모델의 pred값 가짐\n","\n","pred_1 = []\n","for i in range(len(predicted_y_list[0])):\n","    pred_1.append((predicted_y_list[0][i]).cpu().numpy())\n","\n","pred_1_list = np.hstack([pred_1[i] for i in range(10)])\n","\n","\n","pred_2 = []\n","for i in range(len(predicted_y_list[1])):\n","    pred_2.append((predicted_y_list[1][i]).cpu().numpy())\n","\n","pred_2_list = np.hstack([pred_2[i] for i in range(10)])\n","\n","\n","pred_3 = []\n","for i in range(len(predicted_y_list[2])):\n","    pred_3.append((predicted_y_list[2][i]).cpu().numpy())\n","\n","pred_3_list = np.hstack([pred_3[i] for i in range(10)])\n","\n","\n","pred_4 = []\n","for i in range(len(predicted_y_list[3])):\n","    pred_4.append((predicted_y_list[3][i]).cpu().numpy())\n","\n","pred_4_list = np.hstack([pred_4[i] for i in range(10)])\n","\n","\n","# pred_list = 전체 model의 class ensemble 예측 값\n","pred_list = np.vstack([pred_1_list, pred_2_list, pred_3_list, pred_4_list])\n","pred_list.shape\n","\n","\n","pred_list_max = np.max(pred_list, axis=0)\n","pred_list_max.shape\n","pred_list_max[:5]"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"id":"7fyKmwmlZMZD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599832741223,"user_tz":-540,"elapsed":898,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}},"outputId":"3e10c6df-64da-4dfe-a2f5-257b7437af63"},"source":["# test_y_list ==> 4개 key, dict형, 모든 모델의 test_y값 가짐\n","\n","y_1 = []\n","for i in range(len(test_y_list[0])):\n","    y_1.append((test_y_list[0][i]).cpu().numpy())\n","\n","y_1_list = np.hstack([y_1[i] for i in range(10)])\n","\n","\n","y_2 = []\n","for i in range(len(test_y_list[1])):\n","    y_2.append((test_y_list[1][i]).cpu().numpy())\n","\n","y_2_list = np.hstack([y_2[i] for i in range(10)])\n","\n","\n","y_3 = []\n","for i in range(len(test_y_list[2])):\n","    y_3.append((test_y_list[2][i]).cpu().numpy())\n","\n","y_3_list = np.hstack([y_3[i] for i in range(10)])\n","\n","\n","y_4 = []\n","for i in range(len(test_y_list[3])):\n","    y_4.append((test_y_list[3][i]).cpu().numpy())\n","\n","y_4_list = np.hstack([y_4[i] for i in range(10)])\n","\n","\n","# y_list = 전체 model의 class ensemble 예측 값\n","y_list = np.vstack([y_1_list, y_2_list, y_3_list, y_4_list])\n","y_list.shape\n","\n","\n","y_list_max = np.max(y_list, axis=0)\n","y_list_max.shape\n","y_list_max[:5]"],"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3, 8, 8, 0, 6])"]},"metadata":{"tags":[]},"execution_count":77}]},{"cell_type":"code","metadata":{"id":"R5zYE3mBZMPt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599833113356,"user_tz":-540,"elapsed":976,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}},"outputId":"d7ae1d03-9be1-474d-f78f-fb5001f5f8dd"},"source":["compare_list = (pred_list_max == y_list_max)\n","\n","compare_score = list(map(int,compare_list))\n","\n","accuracy_score = np.sum(compare_score)/len(compare_score)\n","\n","print(accuracy_score)"],"execution_count":89,"outputs":[{"output_type":"stream","text":["0.7612\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u53gr3uZbmIf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599833182675,"user_tz":-540,"elapsed":733,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}},"outputId":"339d24e8-c90e-4767-cae5-357644f9bbc6"},"source":["# predicted_y_list ==> 4개 key, dict형, 모든 모델의 pred값 가짐\n","\n","pred_1 = []\n","for i in range(len(predicted_y_list[0])):\n","    pred_1.append((predicted_y_list[0][i]).cpu().numpy())\n","\n","pred_1_list = np.hstack([pred_1[i] for i in range(10)])\n","\n","\n","pred_2 = []\n","for i in range(len(predicted_y_list[1])):\n","    pred_2.append((predicted_y_list[1][i]).cpu().numpy())\n","\n","pred_2_list = np.hstack([pred_2[i] for i in range(10)])\n","\n","\n","# pred_list = 전체 model의 class ensemble 예측 값\n","pred_list = np.vstack([pred_1_list, pred_2_list])\n","\n","pred_list_max = np.max(pred_list, axis=0)\n","pred_list_max.shape\n","pred_list_max[:5]"],"execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3, 8, 8, 0, 6])"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"id":"FnbqwWWed0NW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599833184809,"user_tz":-540,"elapsed":720,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}},"outputId":"6bf53a17-5cfc-460d-f54e-17186e4fd111"},"source":["# test_y_list ==> 4개 key, dict형, 모든 모델의 test_y값 가짐\n","\n","y_1 = []\n","for i in range(len(test_y_list[0])):\n","    y_1.append((test_y_list[0][i]).cpu().numpy())\n","\n","y_1_list = np.hstack([y_1[i] for i in range(10)])\n","\n","\n","y_2 = []\n","for i in range(len(test_y_list[1])):\n","    y_2.append((test_y_list[1][i]).cpu().numpy())\n","\n","y_2_list = np.hstack([y_2[i] for i in range(10)])\n","\n","\n","# y_list = 전체 model의 class ensemble 예측 값\n","y_list = np.vstack([y_1_list, y_2_list])\n","\n","y_list_max = np.max(y_list, axis=0)\n","y_list_max.shape\n","y_list_max[:5]"],"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3, 8, 8, 0, 6])"]},"metadata":{"tags":[]},"execution_count":91}]},{"cell_type":"code","metadata":{"id":"3ATL3zpbd0DH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599833246777,"user_tz":-540,"elapsed":781,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}},"outputId":"c0d158f0-9832-431b-fb35-c4c12c8e6de8"},"source":["compare_list = (pred_list_max == y_list_max)\n","\n","compare_score = list(map(int,compare_list))\n","\n","accuracy_score = np.sum(compare_score)/len(compare_score)\n","\n","print(\"Ensemble model accuracy : {} %\".format(accuracy_score*100))"],"execution_count":96,"outputs":[{"output_type":"stream","text":["Ensemble model accuracy : 81.55 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PNcDUZCcdz5i","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WN37T21BtnyD","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599831157090,"user_tz":-540,"elapsed":1595135,"user":{"displayName":"김정섭","photoUrl":"","userId":"03104285111645443112"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g25BqA-6fTaJ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r0Wi72B6fTYt","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5YNV9b3ZfTJy","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ewoAxtKffTIR","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_dy2a96fS-_","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"37nmdWpofS72","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}